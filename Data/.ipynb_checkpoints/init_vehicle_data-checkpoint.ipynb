{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "7aa1f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3 as sql\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "5c5e2526",
   "metadata": {},
   "outputs": [],
   "source": [
    "## join epa vehicle information to adjusted weight information for 2023-2017 years.\n",
    "epa_df = pd.read_xml(\"/Users/josheverts/Downloads/vehicles.xml\")\n",
    "\n",
    "\n",
    "## load in data from 2000-2016, stored as .csv files by the epa\n",
    "path = \"/Users/josheverts/Documents/Epa_AdjWeights/Excel\"\n",
    "os.chdir(path)\n",
    "## data to join with adjusted weights\n",
    "weight_dfs = []\n",
    "for file in os.listdir():\n",
    "    weight_dfs.append(pd.read_excel(file))\n",
    "# test_data_2023 = pd.read_excel('23-testcar-2022-11-03.xlsx')\n",
    "# test_data_2022 = pd.read_excel('22-testcar-2023-02-28.xlsx')\n",
    "# test_data_2021 = pd.read_excel('21-tstcar-2022-04-15.xlsx')\n",
    "# test_data_2020 = pd.read_excel('20tstcar-2021-03-02.xlsx')\n",
    "# test_data_2019 = pd.read_excel('19tstcar-2020-10-02.xlsx')\n",
    "# test_data_2018 = pd.read_excel('18tstcar-2018-10-24.xlsx')\n",
    "# test_data_2017 = pd.read_excel('17tstcar-2018-05-30.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5d9997",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dfs = [test_data_2023, test_data_2022, test_data_2021,\n",
    "              test_data_2020, test_data_2019, test_data_2018, test_data_2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "f95d3e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load in data from 2000-2016, stored as .csv files by the epa\n",
    "path = \"/Users/josheverts/Documents/Epa_AdjWeights/csv\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "8445cfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_index_adj_weights(adj_weight_df, yr):\n",
    "    if yr >= 10: ## 2010 or later\n",
    "        adj_weight_df_grouped = adj_weight_df.groupby(['Represented Test Veh Make',\n",
    "                                                       'Represented Test Veh Model', \n",
    "                                                       'Veh Mfr Code'], group_keys = False).mean(numeric_only = True)\n",
    "        adj_weight_df_grouped = adj_weight_df_grouped.reset_index()\n",
    "        adj_weight_df_grouped = adj_weight_df_grouped.reset_index()\n",
    "        adj_weight_df_grouped = adj_weight_df_grouped.rename(columns = {'index':'VehicleID'})\n",
    "        rename_dict = {'Model Year': 'Year', 'Represented Test Veh Make':'Make', 'Veh Mfr Code': 'MFRCode',\n",
    "                   'Represented Test Veh Model':'Model', 'Equivalent Test Weight (lbs.)':'AdjWeight'}\n",
    "        epa_adj_weights = adj_weight_df_grouped.rename(rename_dict, axis=1)  \n",
    "        epa_adj_weights = epa_adj_weights[['VehicleID', 'Year', 'MFRCode', 'Make', 'Model', 'AdjWeight']]\n",
    "        epa_adj_weights.astype({'Year': 'int32'})\n",
    "    else:        \n",
    "        return\n",
    "#         adj_weight_df_grouped = adj_weight_df.groupby(['VI_MFR_NM',\n",
    "#                                                        'Represented Test Veh Model', \n",
    "#                                                        'Veh Mfr Code'], group_keys = False).mean(numeric_only = True)\n",
    "#         adj_weight_df_grouped = adj_weight_df_grouped.reset_index()\n",
    "#         adj_weight_df_grouped = adj_weight_df_grouped.reset_index()\n",
    "#         adj_weight_df_grouped = adj_weight_df_grouped.rename(columns = {'index':'VehicleID'})\n",
    "#         rename_dict = {'Model Year': 'Year', 'Represented Test Veh Make':'Make', 'Veh Mfr Code': 'MFRCode',\n",
    "#                    'Represented Test Veh Model':'Model', 'Equivalent Test Weight (lbs.)':'AdjWeight'}\n",
    "#         epa_adj_weights = adj_weight_df_grouped.rename(rename_dict, axis=1)  \n",
    "#         epa_adj_weights = epa_adj_weights[['VehicleID', 'Year', 'MFRCode', 'Make', 'Model', 'AdjWeight']]\n",
    "#         epa_adj_weights.astype({'Year': 'int32'})\n",
    "        \n",
    "        \n",
    "    \n",
    "    return epa_adj_weights\n",
    "\n",
    "def clean_index_vehicle_data(vehicle_df):\n",
    "    \n",
    "    ## rename columns of each df\n",
    "    rename_dict = {'id': 'VehicleID', 'make': 'Make', 'model':'Model', 'mfrCode':'MFRCode', 'range': 'Range',\n",
    "              'rangeHwy': 'RangeHwy', 'year':'Year'}\n",
    "    vehicle_df = vehicle_df.rename(rename_dict, axis=1)\n",
    "    \n",
    "    ## vehicle atvType are:\n",
    "    vehicle_df['atvType'].unique()\n",
    "    ## if None or Diesel, assign ICE\n",
    "    ## if Hybrid assign HEV\n",
    "    ## if Plug-in Hybrid assigh PHEV\n",
    "    ## if FFV assign FCV\n",
    "    def convert_vals(vals):\n",
    "        out = []\n",
    "        for val in vals:\n",
    "            if pd.isna(val) == True or val == 'Diesel':\n",
    "                out.append('ICE')\n",
    "            elif val == 'Hybrid':\n",
    "                out.append('HEV')\n",
    "            elif val == 'Plug-in Hybrid':\n",
    "                out.append('PHEV')\n",
    "            elif val == 'EV':\n",
    "                out.append(val)\n",
    "            elif val == 'FFV':\n",
    "                out.append('FCV')\n",
    "            else:\n",
    "                out.append(None)\n",
    "        return out\n",
    "    new_codes = convert_vals(vehicle_df['atvType'])\n",
    "    vehicle_df['atvType'] = new_codes\n",
    "    vehicle_df = vehicle_df[['VehicleID', 'Year', 'MFRCode', 'Make', 'Model', \n",
    "                             'Range', 'RangeHwy', 'rangeHwyA','atvType', \n",
    "                             'UHighway', 'UCity', 'city08U', 'highway08U', 'combE', \n",
    "                             'combinedUF', 'comb08', 'trany', 'cylinders', 'displ', 'baseModel']]\n",
    "    \n",
    "    return vehicle_df\n",
    "\n",
    "def concat_weight_data(weight_dfs, yrs):\n",
    "    combined = pd.DataFrame()\n",
    "    for df, yr in zip(weight_dfs, yrs):\n",
    "        cleaned = clean_index_adj_weights(df, yr)\n",
    "        combined = pd.concat([combined, cleaned])\n",
    "    combined['Year'] = combined['Year'].astype('int')\n",
    "    combined['VehicleID'] = np.arange(0, len(combined)) ## assign new unique ids\n",
    "    combined = combined.reset_index().drop(['index'], axis = 1)\n",
    "    return combined\n",
    "        \n",
    "    \n",
    "def vehicle_data_join(vehicle_df, combined_weights):\n",
    "    vehicle_df = vehicle_df.copy(); combined_weights = combined_weights.copy()\n",
    "    tempdf = vehicle_df[['VehicleID','Year','Make', 'Model']]\n",
    "    tempdf2 = vehicle_df[['VehicleID', 'Make', 'Model', 'trany', 'displ', 'cylinders', 'atvType']]\n",
    "    vehicle_df['Make'] = vehicle_df['Make'].str.lower()\n",
    "    vehicle_df['baseModel'] = vehicle_df['baseModel'].str.lower()\n",
    "    vehicle_df['Model'] = vehicle_df['Model'].str.lower()\n",
    "    combined_weights['Make'] = combined_weights['Make'].str.lower()\n",
    "    combined_weights['Model'] = combined_weights['Model'].str.lower()\n",
    "    combined_weights['baseModel'] = [i.split(' ')[0] for i in combined_weights['Model']]\n",
    "    adj_join = pd.merge(vehicle_df, combined_weights, how='inner', \n",
    "                        left_on=['Year', 'Make','baseModel'], right_on = ['Year', 'Make','baseModel'])\n",
    "    adj_join_g = adj_join.groupby(['VehicleID_x']).agg({'UHighway': np.mean, 'UCity': np.mean, 'city08U': np.mean, \n",
    "                                                    'Range': np.mean, 'RangeHwy': np.mean, 'rangeHwyA': np.mean,\n",
    "                                                    'highway08U':  np.mean, 'combE': np.mean, 'combinedUF': np.mean, \n",
    "                                                    'comb08': np.mean, 'AdjWeight': np.mean})  \n",
    "    adj_join_g_j = pd.merge(adj_join_g, tempdf2, how = 'inner', left_on='VehicleID_x', right_on='VehicleID')\n",
    "    adj_join_final_cap = pd.merge(adj_join_g_j, tempdf, how = 'inner', left_on='VehicleID', right_on='VehicleID')\n",
    "    adj_join_final_cap_drop = adj_join_final_cap.drop(['Make_x', 'Model_x'], axis = 1)\n",
    "    adj_join_final_cap_drop = adj_join_final_cap_drop.rename({'Make_y': 'Make', 'Model_y': 'Model'}, axis = 1)\n",
    "#     print(adj_join_final_cap_drop.columns)\n",
    "    adj_join_final_cap_drop = adj_join_final_cap_drop[~adj_join_final_cap_drop.duplicated(['Year', 'Make', 'Model', 'trany', 'displ', 'cylinders'])]\n",
    "    cols = adj_join_final_cap_drop.columns.to_list()\n",
    "    cols = cols[::-1]\n",
    "    adj_join_final_cap_drop = adj_join_final_cap_drop[cols]\n",
    "    adj_join_final_cap_drop = adj_join_final_cap_drop.reset_index().drop(['index'], axis = 1)\n",
    "    \n",
    "    return adj_join_final_cap_drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "58b70022",
   "metadata": {},
   "outputs": [],
   "source": [
    "## concatenate .csv files 2010 onwards into one df\n",
    "yrs = []\n",
    "csv_dfs = []\n",
    "for file in os.listdir():\n",
    "    df = pd.DataFrame()\n",
    "    # Check whether file is in text format or not\n",
    "    if file.endswith(\".csv\"):\n",
    "        yrs.append(int(file[:2]))\n",
    "        csv_dfs.append(pd.read_csv(file))\n",
    "combined_csv1016 = concat_weight_data(csv_dfs, yrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "7c7f7d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## join df to epa df\n",
    "epa_df_cleaned = clean_index_vehicle_data(epa_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "0438d7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data_10_16 = vehicle_data_join(epa_df_cleaned, combined_csv1016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "17c5523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## concatenate .excel files 2017 onwards into one df\n",
    "combined_df1723 = concat_weight_data(weight_dfs, np.arange(17,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "d8ff0c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data_17_23 = vehicle_data_join(epa_df_cleaned, combined_df1723)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "3efb9e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## combine joined dataframes to create years 2010-2023\n",
    "joined_data_10_23 = pd.concat([joined_data_10_16, joined_data_17_23])\n",
    "joined_data_10_23['VehicleID'] = np.arange(0, len(joined_data_10_23)) ## assign new unique ids\n",
    "joined_data_10_23 = joined_data_10_23.reset_index().drop(['index'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "1b3badd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data_10_23.to_csv(\"adj_weight_data_join_2010-2023.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "20507059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDLYR_DT: 2009\n",
      "VI_MFR_CD: 20\n",
      "VI_MFR_NM: Chrysler LLC\n",
      "GBE_INDX_NUM: 223\n",
      "OV_ID: L8RTK4922\n",
      "VC_CNFG_NUM: 0\n",
      "CL_NM: CARAVAN FWD\n",
      "CLS_TYP_CD: T\n",
      "GBE_CID_MSR: 241\n",
      "GBE_PLC_IND_CD: N\n",
      "VC_RTD_HP_MSR: 253\n",
      "ECS_CD: nan\n",
      "ECS_CD_0: nan\n",
      "ECS_CD_1: nan\n",
      "ECS_CD_2: nan\n",
      "ECS_CD_3: nan\n",
      "EVCS_CD: 102.0\n",
      "TRNS: L6\n",
      "DRV_SYS_CD: F\n",
      "TOD_CD: 2\n",
      "VC_DSN_ETW_MSR: 5000\n",
      "VC_CMPRSN_RAT_MSR: 10.3\n",
      "VC_AXLE_RAT_MSR: 3.25\n",
      "VC_NV_RAT_MSR: 27.4\n",
      "TPF_ACHP_IND_CD: Y\n",
      "TPF_DYNO_HP_MSR: nan\n",
      "SIL_CD: 1\n",
      "TST_PRC_CD: 21\n",
      "TST_PRPS_CD: 31\n",
      "TST_NUM_ID: 1077668\n",
      "VEH_FL_TYP_CD: 61\n",
      "CH_CD: C\n",
      "AVRG_CD: nan\n",
      "GT_WT_MSR: nan\n",
      "CMYT_HC_FE_MSR: 0.045\n",
      "CMYT_CO_FE_MSR: 0.89\n",
      "CMYT_CO2_FE_MSR: 414.0\n",
      "CMYT_NOX_MSR: 0.01\n",
      "CMYT_PM_MSR: nan\n",
      "GT_RND_ADJ_QTY: 21.4\n",
      "TPF_DYN_TRK_A_MSR: 39.0\n",
      "TPF_DYN_TRK_B_MSR: 0.5805\n",
      "TPF_DYN_TRK_C_MSR: 0.02248\n",
      "TPF_EDYN_TRK_A_MSR: 21.25\n",
      "TPF_EDYN_TRK_B_MSR: 0.17038\n",
      "TPF_EDYN_TRK_C_MSR: 0.0238\n",
      "ENG_CD: FA-600\n",
      "EF_ID: 9CRXJ04.0TN0\n",
      "VC_CYL_CNT: 6\n",
      "TPF_MFR_CSTDN_MSR: nan\n"
     ]
    }
   ],
   "source": [
    "row = pd.read_csv(\"09tstcar.csv\").iloc[50]\n",
    "cols = pd.read_csv(\"09tstcar.csv\").columns\n",
    "for val, name in zip(row, cols):\n",
    "    print(str(name) + \": \" + str(val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c2308aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_df = clean_index_vehicle_data(epa_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "5feea4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data = vehicle_data_join(epa_df, weight_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c0447d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data.to_csv(\"adj_weight_data_join_2017-2023.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
